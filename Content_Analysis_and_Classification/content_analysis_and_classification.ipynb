# ┌────────────────────────────────────────────────────────────────────────────────────┐
# │  Reto: CONTENT ANALYSIS AND CLASSIFICATION (NETFLIX DATASET)                       │
# │  Desarrollado por: Álvaro Rodrigo Moctezuma Ramírez                                │
# └────────────────────────────────────────────────────────────────────────────────────┘

# ──── SECCIÓN 1 ─────────────────────────────────────────────────────────────────
# GESTIÓN DE DEPENDENCIAS Y ENTORNO
# ────────────────────────────────────────────────────────────────────────────────

import subprocess
import sys
import os

def manage_dependencies():
    packages = ["pandas", "numpy", "matplotlib", "seaborn", "plotly", "scikit-learn"]
    print("» VERIFICANDO ENTORNO DE EJECUCIÓN...")
    for package in packages:
        try:
            __import__(package)
        except ImportError:
            print(f"  [ INSTALANDO ] : {package}...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])
    print("» ENTORNO LISTO.\n")

manage_dependencies()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ──── SECCIÓN 2 ─────────────────────────────────────────────────────────────────
# ADQUISICIÓN Y GOBIERNO DE DATOS (DATA QUALITY)
# ────────────────────────────────────────────────────────────────────────────────

print("» CARGANDO DATASET DESDE ORIGEN PÚBLICO...")
url = "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv"
df = pd.read_csv(url)

def data_governance_report(data):
    print("\n---------------------------------------------------------")
    print("  ESTADO DE CALIDAD DE DATOS (DATA QUALITY REPORT)")
    print("---------------------------------------------------------")
    nulls = data.isnull().sum()
    print(nulls[nulls > 0])
    print("---------------------------------------------------------\n")

data_governance_report(df)

print("» EJECUTANDO PIPELINE DE LIMPIEZA...")
# Imputación de valores nulos (Gobierno de Datos)
df['country'] = df['country'].fillna('Unknown')
df['cast'] = df['cast'].fillna('No Data')
df['director'] = df['director'].fillna('Anonymous')

# Conversión de tipos de datos
df['date_added'] = pd.to_datetime(df['date_added'].str.strip())
df['release_year'] = df['release_year'].astype(int)

# ──── SECCIÓN 3 ─────────────────────────────────────────────────────────────────
# ANÁLISIS EXPLORATORIO DE DATOS (EDA)
# ────────────────────────────────────────────────────────────────────────────────

print("» GENERANDO INTELIGENCIA VISUAL...")

# 1. Comparativa de Contenido: Películas vs Series
plt.figure(figsize=(10, 5))
sns.countplot(data=df, x='type', palette='Reds_r')
plt.title('Distribución de Contenido en Netflix')
plt.show()

# 2. Crecimiento de Contenido por Año (Última década)
content_by_year = df[df['release_year'] > 2010]['release_year'].value_counts().sort_index()
fig = px.line(x=content_by_year.index, y=content_by_year.values, 
              title='Crecimiento de Estrenos (2010 - 2021)',
              labels={'x': 'Año', 'y': 'Cantidad de Títulos'})
fig.show()

# ──── SECCIÓN 4 ─────────────────────────────────────────────────────────────────
# MODELADO: CLASIFICACIÓN POR SIMILITUD (NLP)
# ────────────────────────────────────────────────────────────────────────────────

print("» CONSTRUYENDO MOTOR DE CLASIFICACIÓN POR CONTENIDO...")

# Creamos una columna de metadatos combinando descripción, género y elenco
df['features'] = (df['description'] + " " + df['listed_in'] + " " + df['cast']).fillna('')

# Vectorización TF-IDF (Term Frequency-Inverse Document Frequency)
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df['features'])

# Cálculo de Similitud de Coseno
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

def recommend_content(title, n_recommendations=5):
    try:
        idx = df[df['title'].str.lower() == title.lower()].index[0]
        sim_scores = list(enumerate(cosine_sim[idx]))
        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
        content_indices = [i[0] for i in sim_scores[1:n_recommendations+1]]
        
        print(f"\n» PORQUE VISTE '{title}', TE RECOMENDAMOS:")
        return df[['title', 'type', 'listed_in']].iloc[content_indices]
    except IndexError:
        return f"Error: El título '{title}' no se encuentra en el catálogo."

# ──── SECCIÓN 5 ─────────────────────────────────────────────────────────────────
# VALIDACIÓN DEL MODELO
# ────────────────────────────────────────────────────────────────────────────────

# Prueba 1: Serie de Crimen
print(recommend_content('Peaky Blinders'))

# Prueba 2: Película de Ciencia Ficción
print(recommend_content('Inception'))

print("\n» PROCESO FINALIZADO EXITOSAMENTE.")
