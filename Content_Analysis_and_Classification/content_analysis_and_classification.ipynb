# ┌────────────────────────────────────────────────────────────────────────────────────┐
# │  Reto: CONTENT ANALYSIS AND CLASSIFICATION (NETFLIX DATASET)                       │
# │  Desarrollado por: Álvaro Rodrigo Moctezuma Ramírez                                │
# └────────────────────────────────────────────────────────────────────────────────────┘

import subprocess
import sys
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ──── SECCIÓN 0 ─────────────────────────────────────────────────────────────────
# ESTRUCTURA DE GOBIERNO DE DATOS (AUTO-GENERACIÓN)
# ────────────────────────────────────────────────────────────────────────────────

def initialize_project():
    folders = ['data', 'outputs', 'docs']
    print("» INICIALIZANDO ESTRUCTURA DE DIRECTORIOS...")
    for folder in folders:
        if not os.path.exists(folder):
            os.makedirs(folder)
            print(f"  [ CREADO ] : /{folder}")
        else:
            print(f"  [ EXISTE ] : /{folder}")

initialize_project()

# ──── SECCIÓN 1 ─────────────────────────────────────────────────────────────────
# GESTIÓN DE DEPENDENCIAS
# ────────────────────────────────────────────────────────────────────────────────

def manage_dependencies():
    packages = ["pandas", "numpy", "matplotlib", "seaborn", "plotly", "scikit-learn"]
    print("\n» VERIFICANDO ENTORNO DE EJECUCIÓN...")
    for package in packages:
        try:
            __import__(package)
        except ImportError:
            print(f"  [ INSTALANDO ] : {package}...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])
    print("» ENTORNO LISTO.\n")

manage_dependencies()

# ──── SECCIÓN 2 ─────────────────────────────────────────────────────────────────
# ADQUISICIÓN Y GOBIERNO DE DATOS
# ────────────────────────────────────────────────────────────────────────────────

print("» ADQUIRIENDO DATASET...")
url = "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv"
df = pd.read_csv(url)

# Guardar copia local del dataset original (Gobierno de Datos)
df.to_csv('data/netflix_titles_raw.csv', index=False)
print("  [ GUARDADO ] : data/netflix_titles_raw.csv")

def data_governance_report(data):
    print("\n---------------------------------------------------------")
    print("  ESTADO DE CALIDAD DE DATOS (DATA QUALITY REPORT)")
    print("---------------------------------------------------------")
    nulls = data.isnull().sum()
    print(nulls[nulls > 0])
    print("---------------------------------------------------------\n")

data_governance_report(df)

print("» EJECUTANDO PIPELINE DE LIMPIEZA...")
df['country'] = df['country'].fillna('Unknown')
df['cast'] = df['cast'].fillna('No Data')
df['director'] = df['director'].fillna('Anonymous')
df['date_added'] = pd.to_datetime(df['date_added'].str.strip())
df['release_year'] = df['release_year'].astype(int)

# ──── SECCIÓN 3 ─────────────────────────────────────────────────────────────────
# ANÁLISIS EXPLORATORIO (EDA) CON GUARDADO AUTOMÁTICO
# ────────────────────────────────────────────────────────────────────────────────

print("» GENERANDO INTELIGENCIA VISUAL...")

plt.figure(figsize=(10, 5))
sns.countplot(data=df, x='type', palette='Reds_r')
plt.title('Distribución de Contenido en Netflix')
plt.savefig('outputs/content_distribution.png') # Guardado automático
plt.show()

content_by_year = df[df['release_year'] > 2010]['release_year'].value_counts().sort_index()
fig = px.line(x=content_by_year.index, y=content_by_year.values, 
              title='Crecimiento de Estrenos (2010 - 2021)',
              labels={'x': 'Año', 'y': 'Cantidad de Títulos'})
fig.write_html("outputs/growth_report.html") # Guardado automático
fig.show()

# ──── SECCIÓN 4 ─────────────────────────────────────────────────────────────────
# MODELADO NLP
# ────────────────────────────────────────────────────────────────────────────────

print("» CONSTRUYENDO MOTOR DE CLASIFICACIÓN...")
df['features'] = (df['description'] + " " + df['listed_in'] + " " + df['cast']).fillna('')
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df['features'])
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

def recommend_content(title, n_recommendations=5):
    try:
        idx = df[df['title'].str.lower() == title.lower()].index[0]
        sim_scores = list(enumerate(cosine_sim[idx]))
        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
        content_indices = [i[0] for i in sim_scores[1:n_recommendations+1]]
        
        print(f"\n» RECOMENDACIONES PARA '{title}':")
        return df[['title', 'type', 'listed_in']].iloc[content_indices]
    except IndexError:
        return f"Error: '{title}' no encontrado."

# ──── SECCIÓN 5 ─────────────────────────────────────────────────────────────────
# VALIDACIÓN
# ────────────────────────────────────────────────────────────────────────────────

print(recommend_content('Peaky Blinders'))
print(recommend_content('Inception'))

print("\n» PROCESO FINALIZADO. REVISA LA CARPETA /outputs PARA LOS REPORTES.")
